# Simple-LLM-Trainers

## Overview
Simple-LLM-Trainers is a lightweight, versatile, and user-friendly collection of trainers specifically designed for Large Language Model (LLM) training. This toolkit is tailored to support models and datasets from Hugging Face, a leader in the field of natural language processing. Our trainers are developed exclusively with PyTorch, ensuring a smooth and efficient development experience.

## Features
1. Ease of Use: Simple-LLM-Trainers is built with simplicity in mind, making it accessible for both beginners and advanced users.
2. Flexibility: Supports both pretraining and finetuning of Large Language Models, catering to a wide range of applications and research needs.
3. PyTorch Integration: Fully implemented in PyTorch, offering seamless integration with existing PyTorch workflows.

## Current Implementation
1. BaseTrainer: CPU, single GPU, and Data Parallel training.
2. DDPTrainer: Distributed Data Parallel training.
3. PipeTrainer:
4. FSDPTrainer:
